{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BBS_scrape.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moebot3000/SpecialistCode/blob/main/BBS_scrape.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkqOdiLpIYcj"
      },
      "source": [
        "# BBS licensure records"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTM5BcQzIpXJ"
      },
      "source": [
        "This program can be used to get data from the BBS website. It looks up each student who has graduated from our program in a spreadsheet to find out if they registered as an Associate and if they got licensed by the BBS."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMt1C4lwJWJI"
      },
      "source": [
        "*Get libraries that will be used in the analysis. These are just mini-programs.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6r0RYl-ISDJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "7b9c6e62-4b8a-4e18-9f3e-fda479d38d02"
      },
      "source": [
        "from lxml import html\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from math import isnan\n",
        "import scipy as sp\n",
        "from datetime import datetime  \n",
        "from datetime import timedelta\n",
        "from google.colab import files\n",
        "!pip install --upgrade --quiet gspread\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "from gspread_dataframe import get_as_dataframe\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/o",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMPuooZEJuha"
      },
      "source": [
        "*Next, upload an excel spreadsheet (saved as a .csv) of all the data from FileMaker. This will be used to get a list of student names. Here it's coming from my GitHub Ed account, but it can also come from Google Drive or wherever.*\n",
        "\n",
        "*Below, you can see the first few rows of the spreadsheet.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmSqUaoVJ0oj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "792d44ea-0ffe-4914-84d8-2ed7a6be5349"
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/moebot3000/Annual_Report_Self_Study_2019_wi/master/FM_10092019_background.csv?token=AL3PAHR2JDGKL7RNGTBYYOS5VTRFI'\n",
        "FM = pd.read_csv(url)\n",
        "FM.head()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-348c41291407>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://raw.githubusercontent.com/moebot3000/Annual_Report_Self_Study_2019_wi/master/FM_10092019_background.csv?token=AL3PAHR2JDGKL7RNGTBYYOS5VTRFI'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mFM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mFM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f_dIzDiL4kp"
      },
      "source": [
        "*Clean up that spreadsheet and pull out just the parts used in this analysis. Again, you can see the top of the cleaned up version below.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJ0HLRtfKWgi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "6d1f5f73-464e-4710-cb9d-00d0dc8ebdc1"
      },
      "source": [
        "stus = FM.filter(['NameLast','NameFirst','Sem_Year_Admitted','Status_Most_Recent'])\n",
        "stus.dropna(how='all',inplace=True)\n",
        "stus['entered'] = stus.Sem_Year_Admitted.str.extract('(\\d+)')\n",
        "stus.reset_index(inplace=True)\n",
        "stus['NameLast'] = stus['NameLast'].str.upper()\n",
        "stus['NameFirst'] = stus['NameFirst'].str.upper()\n",
        "stus = stus[stus['Status_Most_Recent'] == 'Graduated']\n",
        "stus.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d540569d5de9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NameLast'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'NameFirst'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Sem_Year_Admitted'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Status_Most_Recent'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mstus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'all'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'entered'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSem_Year_Admitted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'(\\d+)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NameLast'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NameLast'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'FM' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mwny1UlxMkV-"
      },
      "source": [
        "*Use those names to access the BBS website to look everybody up and see what kind of licenses they've got/when they were issued. That info gets added to the spreadsheet.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTyr7dofMewf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "6baf949c-2be5-49b5-9321-02f4cac77c5b"
      },
      "source": [
        "mft_first_date = {}\n",
        "mft_first_type = {}\n",
        "mft_first_num = {}\n",
        "for i,j in zip(stus['NameLast'], stus['NameFirst']):\n",
        "    body = {'lastName':i, 'firstName':j, 'licenseType':'217'}\n",
        "    con = requests.post('https://search.dca.ca.gov/results', data=body)\n",
        "    s1 = con.text\n",
        "    s2 = i+', '+j\n",
        "    placetocut = s1.find('/de',s1.find(s2))\n",
        "    cuttext = s1[placetocut:]\n",
        "    placetocut_lictype = cuttext.find('</strong>', cuttext.find('class'))\n",
        "    cuttext_lictype = cuttext[placetocut_lictype:]\n",
        "    lic_type = cuttext_lictype[9:18]\n",
        "    endgone = cuttext.rsplit(sep='\\' cl')\n",
        "    linkstring=endgone[0]\n",
        "    newlink= 'https://search.dca.ca.gov'+linkstring\n",
        "    try:\n",
        "        con2 = requests.get(newlink)\n",
        "        s3=con2.text\n",
        "        placetocut2 = s3.find('ate\">')\n",
        "        cuttext2 = s3[placetocut2:]\n",
        "        endgone2 = cuttext2.rsplit(sep='</p>')\n",
        "        messyissue=endgone2[0]\n",
        "        firstdate = messyissue.replace('ate\">','')\n",
        "        placetocut_licnum = s3.find('Licensing details for: ')\n",
        "        cuttext_licnum = s3[placetocut_licnum:]\n",
        "        lic_num = re.search(r'\\d+', cuttext_licnum).group()\n",
        "        mft_first_date.update({s2 : firstdate})\n",
        "        mft_first_type.update({s2 : lic_type})\n",
        "        mft_first_num.update({s2: lic_num})\n",
        "    except requests.ConnectionError:\n",
        "        mft_first_date.update({s2 : 'NaN'})\n",
        "        mft_first_type.update({s2 : 'NaN'})\n",
        "        mft_first_num.update({s2: 'NaN'})\n",
        "\n",
        "mft_second_date = {}\n",
        "mft_second_type = {}\n",
        "mft_second_num = {}\n",
        "for i,j in zip(stus['NameLast'], stus['NameFirst']):\n",
        "    body = {'lastName':i, 'firstName':j, 'licenseType':'217'}\n",
        "    con = requests.post('https://search.dca.ca.gov/results', data=body)\n",
        "    s1 = con.text\n",
        "    s2 = i+', '+j\n",
        "    placetocut = s1.find('/de',s1.find(s2))\n",
        "    cuttext = s1[placetocut:]\n",
        "    placetocut2 = cuttext.find('/de',cuttext.find(s2))\n",
        "    cuttext2 = cuttext[placetocut2:]\n",
        "    placetocut_lictype = cuttext2.find('</strong>', cuttext2.find('class'))\n",
        "    cuttext_lictype = cuttext2[placetocut_lictype:]\n",
        "    lic_type = cuttext_lictype[9:18]\n",
        "    endgone = cuttext2.rsplit(sep='\\' cl')\n",
        "    linkstring=endgone[0]\n",
        "    newlink= 'https://search.dca.ca.gov'+linkstring\n",
        "    try:\n",
        "        con2 = requests.get(newlink)\n",
        "        s3=con2.text\n",
        "        placetocut2 = s3.find('ate\">')\n",
        "        cuttext2 = s3[placetocut2:]\n",
        "        endgone2 = cuttext2.rsplit(sep='</p>')\n",
        "        messyissue=endgone2[0]\n",
        "        seconddate = messyissue.replace('ate\">','')\n",
        "        placetocut_licnum = s3.find('Licensing details for: ')\n",
        "        cuttext_licnum = s3[placetocut_licnum:]\n",
        "        lic_num = re.search(r'\\d+', cuttext_licnum).group()\n",
        "        mft_second_date.update({s2 : seconddate})\n",
        "        mft_second_type.update({s2 : lic_type})\n",
        "        mft_second_num.update({s2: lic_num})\n",
        "    except requests.ConnectionError:\n",
        "        mft_second_date.update({s2 : 'NaN'})\n",
        "        mft_second_type.update({s2 : 'NaN'})\n",
        "        mft_second_num.update({s2: 'NaN'})\n",
        "\n",
        "stus['comboname'] = stus['NameLast']+', '+stus['NameFirst']\n",
        "mftseconddatename = pd.DataFrame.from_dict(mft_second_date, orient='index', columns=['mft_second_date'])\n",
        "mftseconddatetype = pd.DataFrame.from_dict(mft_second_type, orient='index', columns=['mft_second_type'])\n",
        "mftseconddatenum = pd.DataFrame.from_dict(mft_second_num, orient='index', columns=['mft_second_num'])\n",
        "stusecond = stus.join(mftseconddatename, on='comboname', how='left', lsuffix='_left', rsuffix='_right')\n",
        "stusecondtype = stusecond.join(mftseconddatetype, on='comboname', how='left', lsuffix='_left', rsuffix='_right')\n",
        "stusecondtypes = stusecondtype.join(mftseconddatenum, on='comboname', how='left', lsuffix='_left', rsuffix='_right')\n",
        "\n",
        "mftfirstdatename = pd.DataFrame.from_dict(mft_first_date, orient='index', columns=['mft_first_date'])\n",
        "mftfirstdatetype = pd.DataFrame.from_dict(mft_first_type, orient='index', columns=['mft_first_type'])\n",
        "mftfirstdatenum = pd.DataFrame.from_dict(mft_first_num, orient='index', columns=['mft_first_num'])\n",
        "stusecondtype_first = stusecondtypes.join(mftfirstdatename, on='comboname', how='left', lsuffix='_left', rsuffix='_right')\n",
        "stu_secondtype_firsttype = stusecondtype_first.join(mftfirstdatetype, on='comboname', how='left', lsuffix='_left', rsuffix='_right')\n",
        "stu_secondtype_firsttypes = stu_secondtype_firsttype.join(mftfirstdatenum, on='comboname', how='left', lsuffix='_left', rsuffix='_right')\n",
        "\n",
        "stu_secondtype_firsttypes.head()\n",
        "\n",
        "todaysdate = datetime.today().strftime('%m%d%Y')\n",
        "output = 'stu_secondtype_firsttypes_' + todaysdate + '.csv'\n",
        "stu_secondtype_firsttypes.to_csv(output)\n",
        "files.download(output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-0ff9ad3c58a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'stu_secondtype_firsttypes_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtodaysdate\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0mstu_secondtype_firsttypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0;34m'port'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m       \u001b[0;34m'path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m       \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m   })\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: TypeError: Failed to fetch"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slOqGtJmsxi0"
      },
      "source": [
        "## RUN FROM HERE 09242019\n",
        "\n",
        "*Do the same thing, but for PCC licensure this time.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBVucohmsw4l"
      },
      "source": [
        "pcc_first_date = {}\n",
        "pcc_first_type = {}\n",
        "pcc_first_num = {}\n",
        "for i,j in zip(stus['NameLast'], stus['NameFirst']):\n",
        "    body = {'lastName':i, 'firstName':j, 'licenseType':'221'}\n",
        "    con = requests.post('https://search.dca.ca.gov/results', data=body)\n",
        "    s1 = con.text\n",
        "    s2 = i+', '+j\n",
        "    placetocut = s1.find('/de',s1.find(s2))\n",
        "    cuttext = s1[placetocut:]\n",
        "    placetocut_lictype = cuttext.find('</strong>', cuttext.find('class'))\n",
        "    cuttext_lictype = cuttext[placetocut_lictype:]\n",
        "    lic_type = cuttext_lictype[9:18]\n",
        "    endgone = cuttext.rsplit(sep='\\' cl')\n",
        "    linkstring=endgone[0]\n",
        "    newlink= 'https://search.dca.ca.gov'+linkstring\n",
        "    try:\n",
        "        con2 = requests.get(newlink)\n",
        "        s3=con2.text\n",
        "        placetocut2 = s3.find('ate\">')\n",
        "        cuttext2 = s3[placetocut2:]\n",
        "        endgone2 = cuttext2.rsplit(sep='</p>')\n",
        "        messyissue=endgone2[0]\n",
        "        firstdate = messyissue.replace('ate\">','')\n",
        "        placetocut_licnum = s3.find('Licensing details for: ')\n",
        "        cuttext_licnum = s3[placetocut_licnum:]\n",
        "        lic_num = re.search(r'\\d+', cuttext_licnum).group()\n",
        "        pcc_first_date.update({s2 : firstdate})\n",
        "        pcc_first_type.update({s2 : lic_type})\n",
        "        pcc_first_num.update({s2: lic_num})\n",
        "    except requests.ConnectionError:\n",
        "        pcc_first_date.update({s2 : 'NaN'})\n",
        "        pcc_first_type.update({s2 : 'NaN'})\n",
        "        pcc_first_num.update({s2: 'NaN'})\n",
        "\n",
        "pcc_second_date = {}\n",
        "pcc_second_type = {}\n",
        "pcc_second_num = {}\n",
        "for i,j in zip(stus['NameLast'], stus['NameFirst']):\n",
        "    body = {'lastName':i, 'firstName':j, 'licenseType':'221'}\n",
        "    con = requests.post('https://search.dca.ca.gov/results', data=body)\n",
        "    s1 = con.text\n",
        "    s2 = i+', '+j\n",
        "    placetocut = s1.find('/de',s1.find(s2))\n",
        "    cuttext = s1[placetocut:]\n",
        "    placetocut2 = cuttext.find('/de',cuttext.find(s2))\n",
        "    cuttext2 = cuttext[placetocut2:]\n",
        "    placetocut_lictype = cuttext2.find('</strong>', cuttext2.find('class'))\n",
        "    cuttext_lictype = cuttext2[placetocut_lictype:]\n",
        "    lic_type = cuttext_lictype[9:18]\n",
        "    endgone = cuttext2.rsplit(sep='\\' cl')\n",
        "    linkstring=endgone[0]\n",
        "    newlink= 'https://search.dca.ca.gov'+linkstring\n",
        "    try:\n",
        "        con2 = requests.get(newlink)\n",
        "        s3=con2.text\n",
        "        placetocut2 = s3.find('ate\">')\n",
        "        cuttext2 = s3[placetocut2:]\n",
        "        endgone2 = cuttext2.rsplit(sep='</p>')\n",
        "        messyissue=endgone2[0]\n",
        "        seconddate = messyissue.replace('ate\">','')\n",
        "        placetocut_licnum = s3.find('Licensing details for: ')\n",
        "        cuttext_licnum = s3[placetocut_licnum:]\n",
        "        lic_num = re.search(r'\\d+', cuttext_licnum).group()\n",
        "        pcc_second_date.update({s2 : seconddate})\n",
        "        pcc_second_type.update({s2 : lic_type})\n",
        "        pcc_second_num.update({s2: lic_num})\n",
        "    except requests.ConnectionError:\n",
        "        pcc_second_date.update({s2 : 'NaN'})\n",
        "        pcc_second_type.update({s2 : 'NaN'})\n",
        "        pcc_second_num.update({s2: 'NaN'})\n",
        "\n",
        "pccseconddatename = pd.DataFrame.from_dict(pcc_second_date, orient='index', columns=['pcc_second_date'])\n",
        "pccseconddatetype = pd.DataFrame.from_dict(pcc_second_type, orient='index', columns=['pcc_second_type'])\n",
        "pccseconddatenum = pd.DataFrame.from_dict(pcc_second_num, orient='index', columns=['pcc_second_num'])\n",
        "stu2second = stu_secondtype_firsttypes.join(pccseconddatename, on='comboname', how='left', lsuffix='_left', rsuffix='_right')\n",
        "stu2secondtype = stu2second.join(pccseconddatetype, on='comboname', how='left', lsuffix='_left', rsuffix='_right')\n",
        "stu2secondtypes = stu2second.join(pccseconddatenum, on='comboname', how='left', lsuffix='_left', rsuffix='_right')\n",
        "\n",
        "pccfirstdatename = pd.DataFrame.from_dict(pcc_first_date, orient='index', columns=['pcc_first_date'])\n",
        "pccfirstdatetype = pd.DataFrame.from_dict(pcc_first_type, orient='index', columns=['pcc_first_type'])\n",
        "pccfirstdatenum = pd.DataFrame.from_dict(pcc_first_num, orient='index', columns=['pcc_first_num'])\n",
        "stu2secondtype_first = stu2secondtypes.join(pccfirstdatename, on='comboname', how='left', lsuffix='_left', rsuffix='_right')\n",
        "stu2_secondtype_firsttype = stu2secondtype_first.join(pccfirstdatetype, on='comboname', how='left', lsuffix='_left', rsuffix='_right')\n",
        "stu2_secondtype_firsttypes = stu2_secondtype_firsttype.join(pccfirstdatenum, on='comboname', how='left', lsuffix='_left', rsuffix='_right')\n",
        "\n",
        "stu2_secondtype_firsttypes.head()\n",
        "\n",
        "spreadsheet = 'stu2_secondtype_firsttypes_' + todaysdate + '.csv'\n",
        "stu2_secondtype_firsttypes.to_csv(spreadsheet)\n",
        "files.download(spreadsheet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A59vcNEwTkqV"
      },
      "source": [
        "*Do some calculations to make sure that the dates are reasonable (in case there was someone else with the same name on the BBS site, for instance), and get rid of all the junk in the sheet that is not needed.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yt8TcqNTQVM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "2e2f2f67-9a2e-4633-db99-b1fdb8c54b90"
      },
      "source": [
        "stu2_secondtype_firsttypes['entry'] = \"09/01/\" + stu2_secondtype_firsttypes['entered']\n",
        "stu2_secondtype_firsttypes['entryy'] = pd.to_datetime(stu2_secondtype_firsttypes['entry'])\n",
        "stu2_secondtype_firsttypes['graddate'] = stu2_secondtype_firsttypes['entryy'] + timedelta(days=730)\n",
        "\n",
        "# stu2_secondtype_firsttypes['firstdatetime'] = pd.to_datetime(stu2_secondtype_firsttypes['first_date']) ## start here with mft, pcc labels\n",
        "# stu2_secondtype_firsttypes['seconddatetime'] = pd.to_datetime(stu2_secondtype_firsttypes['second_date'])\n",
        "\n",
        "# def first_reasonable(c):\n",
        "#     if (c['firstdatetime'] - c['graddate']) < timedelta(days=-500):\n",
        "#         return 'NaN'\n",
        "#     else:\n",
        "#         return c['firstdatetime']\n",
        "# stu2_secondtype_firsttypes['first_reasonable'] = stu2_secondtype_firsttypes.apply(first_reasonable, axis=1)\n",
        "\n",
        "# def second_reasonable(c):\n",
        "#     if (c['seconddatetime'] - c['graddate']) < timedelta(days=-500):\n",
        "#         return 'NaN'\n",
        "#     else:\n",
        "#         return c['seconddatetime']\n",
        "# stu2_secondtype_firsttypes['second_reasonable'] = stu2_secondtype_firsttypes.apply(second_reasonable, axis=1)\n",
        "\n",
        "# stu2_secondtype_firsttypes\n",
        "\n",
        "# studates = stu2_secondtype_firsttypes.filter(['NameLast','NameFirst','comboname','entryy','graddate','first_type','first_reasonable','second_type','second_reasonable'])\n",
        "\n",
        "lic = {}\n",
        "for a,b,i,j,z in zip(studates['first_type'],studates['first_reasonable'],studates['second_type'],studates['second_reasonable'],studates['comboname']):\n",
        "    if a == 'Licensed ':\n",
        "        lic_date = b\n",
        "    elif i == 'Licensed ':\n",
        "        lic_date = j\n",
        "    else:\n",
        "        lic_date = 'NaN'\n",
        "    lic.update({z : lic_date})   \n",
        "lic_dates = pd.DataFrame.from_dict(lic, orient='index', columns=['lic_date'])\n",
        "studates_lic = studates.join(lic_dates, on='comboname', how='left', lsuffix='_left', rsuffix='_right')\n",
        "\n",
        "assoc = {}\n",
        "for a,b,i,j,z in zip(studates['first_type'],studates['first_reasonable'],studates['second_type'],studates['second_reasonable'],studates['comboname']):\n",
        "    if a == 'Associate':\n",
        "        assoc_date = b\n",
        "    elif i == 'Associate':\n",
        "        assoc_date = j\n",
        "    else:\n",
        "        assoc_date = 'NaN'\n",
        "    assoc.update({z : assoc_date})   \n",
        "assoc_dates = pd.DataFrame.from_dict(assoc, orient='index', columns=['assoc_date'])\n",
        "studates_lic_assoc = studates_lic.join(assoc_dates, on='comboname', how='left', lsuffix='_left', rsuffix='_right')\n",
        "\n",
        "justdates = studates_lic_assoc.filter(['NameLast','NameFirst','entryy','assoc_date','lic_date'])\n",
        "justdates.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-1d3c48d22844>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstu2_secondtype_firsttypes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'entry'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"09/01/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstu2_secondtype_firsttypes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'entered'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mstu2_secondtype_firsttypes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'entryy'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstu2_secondtype_firsttypes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'entry'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstu2_secondtype_firsttypes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'graddate'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstu2_secondtype_firsttypes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'entryy'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m730\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# stu2_secondtype_firsttypes['firstdatetime'] = pd.to_datetime(stu2_secondtype_firsttypes['first_date']) ## start here with mft, pcc labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'stu2_secondtype_firsttypes' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkFm-3_0VtNh"
      },
      "source": [
        "*Pull all the people who got licensed in the last year and make a new spreadsheet. Download that spreadsheet so it can be used in Excel.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnWhdaqyV2IC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "9f78384e-9dbf-4da4-c15a-49db8264a912"
      },
      "source": [
        "dateayrago = datetime.today() - pd.DateOffset(years=1)\n",
        "lastyear = justdates['lic_date'] > dateayrago\n",
        "liclastyear = justdates[lastyear].filter(['NameLast','NameFirst','lic_date'])\n",
        "liclastyear.rename(columns={\"NameLast\": \"Last name\", \"NameFirst\": \"First name\", \"lic_date\": \"MFT License issue date\"}, inplace=True)\n",
        "todaysdate = datetime.today().strftime('%m%d%Y')\n",
        "filename = 'BBS_licensure_dates_for_last_year_' + todaysdate + '.csv'\n",
        "liclastyear.to_csv(filename)\n",
        "files.download(filename)\n",
        "liclastyear.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-39b9807e2c8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdateayrago\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoday\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDateOffset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myears\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlastyear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjustdates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lic_date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mdateayrago\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mliclastyear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjustdates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlastyear\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NameLast'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'NameFirst'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'lic_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mliclastyear\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"NameLast\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Last name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"NameFirst\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"First name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lic_date\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"MFT License issue date\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtodaysdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoday\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%m%d%Y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'datetime' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wo2mTT2wdPgA"
      },
      "source": [
        "*Same thing, but this time we're exporting all the data (including the last year).*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZYkWoO9Z6Qy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "07661d3b-aa9a-434d-f8c7-2c9e98f07876"
      },
      "source": [
        "licall = justdates.filter(['NameLast','NameFirst','lic_date'])\n",
        "licall.rename(columns={\"NameLast\": \"Last name\", \"NameFirst\": \"First name\", \"lic_date\": \"MFT License issue date\"}, inplace=True)\n",
        "licall.dropna(inplace=True)\n",
        "todaysdate = datetime.today().strftime('%m%d%Y')\n",
        "filed = 'BBS_licensure_dates_all_data_' + todaysdate + '.csv'\n",
        "licall.to_csv(filed)\n",
        "filed.download(filed)\n",
        "licall.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-1fc7ab140436>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlicall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjustdates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NameLast'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'NameFirst'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'lic_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlicall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"NameLast\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Last name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"NameFirst\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"First name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lic_date\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"MFT License issue date\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlicall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtodaysdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoday\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%m%d%Y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfiled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'BBS_licensure_dates_all_data_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtodaysdate\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'justdates' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svrCUFSXUxU1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWvOaS9pQyWJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "ed1704fb-90fe-4c3f-d83e-9e2f4449a7e1"
      },
      "source": [
        "# Make sure full product name strings are included\n",
        "# pd.set_option('max_colwidth', 75)\n",
        "\n",
        "# import amazon purchases spreadsheet from google drive\n",
        "spreadsheet = gc.open('BBS_licensure_dates_all_data_09242019')\n",
        "sheet =  spreadsheet.get_worksheet(0)\n",
        "everything = pd.DataFrame(sheet.get_all_records())\n",
        "everything.rename(columns={\"First name\": \"NameFirst\", \"Last name\": \"NameLast\"}, inplace=True)\n",
        "everything.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-fa12a28b81a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# import amazon purchases spreadsheet from google drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mspreadsheet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'BBS_licensure_dates_all_data_09242019'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0msheet\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mspreadsheet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_worksheet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0meverything\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msheet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'gc' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHu5Xm5BSLXs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "outputId": "fd22f84a-f20e-419a-d65d-721d03ee0bb4"
      },
      "source": [
        "ready = everything.merge(stus, on=['NameFirst','NameLast',])\n",
        "ready['latlic'] = (pd.to_datetime(ready['License issue date']) - pd.to_datetime(ready['entered']) - pd.Timedelta(days=1000)) / pd.Timedelta(days=365)\n",
        "fullydone = ready[ready['entered'].astype(int) <= 2010]\n",
        "print(fullydone['latlic'].median())\n",
        "fullydone.describe()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-d89972a5d77f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meverything\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NameFirst'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'NameLast'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'latlic'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'License issue date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'entered'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m365\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfullydone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'entered'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m2010\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfullydone\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'latlic'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfullydone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'everything' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_-XsfYHZXAN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "dd345461-d8da-402c-f838-dfbc65df5788"
      },
      "source": [
        "todaysdate = datetime.today().strftime('%m%d%Y')\n",
        "filed = 'fully_done_' + todaysdate + '.csv'\n",
        "fullydone.to_csv(filed)\n",
        "files.download(filed)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-587599374068>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtodaysdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoday\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%m%d%Y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfiled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'fully_done_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtodaysdate\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfullydone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'datetime' is not defined"
          ]
        }
      ]
    }
  ]
}
